{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "80f65d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import VotingClassifier,StackingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1e0ec876",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('glass.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "955d85b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214, 10)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1c1a5da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    76\n",
       "1    70\n",
       "7    29\n",
       "3    17\n",
       "5    13\n",
       "6     9\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Type'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "465c3e0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RI      0\n",
       "Na      0\n",
       "Mg      0\n",
       "Al      0\n",
       "Si      0\n",
       "K       0\n",
       "Ca      0\n",
       "Ba      0\n",
       "Fe      0\n",
       "Type    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "309fb216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas_profiling.ProfileReport(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "5e8ba006",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d09ac5a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.52101</td>\n",
       "      <td>13.64</td>\n",
       "      <td>4.49</td>\n",
       "      <td>1.10</td>\n",
       "      <td>71.78</td>\n",
       "      <td>0.06</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.51761</td>\n",
       "      <td>13.89</td>\n",
       "      <td>3.60</td>\n",
       "      <td>1.36</td>\n",
       "      <td>72.73</td>\n",
       "      <td>0.48</td>\n",
       "      <td>7.83</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.51618</td>\n",
       "      <td>13.53</td>\n",
       "      <td>3.55</td>\n",
       "      <td>1.54</td>\n",
       "      <td>72.99</td>\n",
       "      <td>0.39</td>\n",
       "      <td>7.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.51766</td>\n",
       "      <td>13.21</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1.29</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.57</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.51742</td>\n",
       "      <td>13.27</td>\n",
       "      <td>3.62</td>\n",
       "      <td>1.24</td>\n",
       "      <td>73.08</td>\n",
       "      <td>0.55</td>\n",
       "      <td>8.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>1.51623</td>\n",
       "      <td>14.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.88</td>\n",
       "      <td>72.61</td>\n",
       "      <td>0.08</td>\n",
       "      <td>9.18</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>1.51685</td>\n",
       "      <td>14.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.99</td>\n",
       "      <td>73.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.40</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>1.52065</td>\n",
       "      <td>14.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.02</td>\n",
       "      <td>73.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.44</td>\n",
       "      <td>1.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1.51651</td>\n",
       "      <td>14.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.94</td>\n",
       "      <td>73.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.48</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>1.51711</td>\n",
       "      <td>14.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>73.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.62</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          RI     Na    Mg    Al     Si     K    Ca    Ba   Fe  Type\n",
       "0    1.52101  13.64  4.49  1.10  71.78  0.06  8.75  0.00  0.0     1\n",
       "1    1.51761  13.89  3.60  1.36  72.73  0.48  7.83  0.00  0.0     1\n",
       "2    1.51618  13.53  3.55  1.54  72.99  0.39  7.78  0.00  0.0     1\n",
       "3    1.51766  13.21  3.69  1.29  72.61  0.57  8.22  0.00  0.0     1\n",
       "4    1.51742  13.27  3.62  1.24  73.08  0.55  8.07  0.00  0.0     1\n",
       "..       ...    ...   ...   ...    ...   ...   ...   ...  ...   ...\n",
       "209  1.51623  14.14  0.00  2.88  72.61  0.08  9.18  1.06  0.0     7\n",
       "210  1.51685  14.92  0.00  1.99  73.06  0.00  8.40  1.59  0.0     7\n",
       "211  1.52065  14.36  0.00  2.02  73.42  0.00  8.44  1.64  0.0     7\n",
       "212  1.51651  14.38  0.00  1.94  73.61  0.00  8.48  1.57  0.0     7\n",
       "213  1.51711  14.23  0.00  2.08  73.36  0.00  8.62  1.67  0.0     7\n",
       "\n",
       "[213 rows x 10 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "fcc215e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = RandomOverSampler()\n",
    "X,y = sample.fit_resample(data.drop(columns=['Type']), data['Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "7b05babd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample = pd.concat([X,y], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e69598be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    76\n",
       "2    76\n",
       "3    76\n",
       "5    76\n",
       "6    76\n",
       "7    76\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample['Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "cbc0114e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = StandardScaler()\n",
    "X_scale = pd.DataFrame(scale.fit_transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "62ed8334",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sample_scale = pd.concat([X_scale,y], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5eea6871",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>K</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.005995</td>\n",
       "      <td>-0.037941</td>\n",
       "      <td>1.521530</td>\n",
       "      <td>-0.763869</td>\n",
       "      <td>-0.969247</td>\n",
       "      <td>-0.481384</td>\n",
       "      <td>-0.212195</td>\n",
       "      <td>-0.414563</td>\n",
       "      <td>-0.457655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.159261</td>\n",
       "      <td>0.212652</td>\n",
       "      <td>0.947370</td>\n",
       "      <td>-0.310299</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>-0.011003</td>\n",
       "      <td>-0.841935</td>\n",
       "      <td>-0.414563</td>\n",
       "      <td>-0.457655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.649353</td>\n",
       "      <td>-0.148202</td>\n",
       "      <td>0.915114</td>\n",
       "      <td>0.003711</td>\n",
       "      <td>0.311630</td>\n",
       "      <td>-0.111799</td>\n",
       "      <td>-0.876160</td>\n",
       "      <td>-0.414563</td>\n",
       "      <td>-0.457655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.142124</td>\n",
       "      <td>-0.468960</td>\n",
       "      <td>1.005431</td>\n",
       "      <td>-0.432414</td>\n",
       "      <td>-0.090629</td>\n",
       "      <td>0.089793</td>\n",
       "      <td>-0.574980</td>\n",
       "      <td>-0.414563</td>\n",
       "      <td>-0.457655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.224378</td>\n",
       "      <td>-0.408818</td>\n",
       "      <td>0.960273</td>\n",
       "      <td>-0.519639</td>\n",
       "      <td>0.406902</td>\n",
       "      <td>0.067394</td>\n",
       "      <td>-0.677655</td>\n",
       "      <td>-0.414563</td>\n",
       "      <td>-0.457655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>-0.303204</td>\n",
       "      <td>1.074692</td>\n",
       "      <td>-1.375076</td>\n",
       "      <td>0.806181</td>\n",
       "      <td>0.343387</td>\n",
       "      <td>-0.548582</td>\n",
       "      <td>-0.362785</td>\n",
       "      <td>2.393498</td>\n",
       "      <td>0.311712</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>-0.426584</td>\n",
       "      <td>0.884241</td>\n",
       "      <td>-1.375076</td>\n",
       "      <td>0.771291</td>\n",
       "      <td>0.629203</td>\n",
       "      <td>-0.548582</td>\n",
       "      <td>-0.369630</td>\n",
       "      <td>2.358176</td>\n",
       "      <td>0.215541</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>-0.652781</td>\n",
       "      <td>1.275166</td>\n",
       "      <td>-1.375076</td>\n",
       "      <td>1.277195</td>\n",
       "      <td>0.639788</td>\n",
       "      <td>-0.548582</td>\n",
       "      <td>-0.239575</td>\n",
       "      <td>0.768708</td>\n",
       "      <td>-0.457655</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>-0.258650</td>\n",
       "      <td>1.275166</td>\n",
       "      <td>-1.375076</td>\n",
       "      <td>0.457281</td>\n",
       "      <td>0.311630</td>\n",
       "      <td>-0.548582</td>\n",
       "      <td>-0.308025</td>\n",
       "      <td>2.322855</td>\n",
       "      <td>-0.457655</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>0.104635</td>\n",
       "      <td>0.643672</td>\n",
       "      <td>0.728028</td>\n",
       "      <td>1.189970</td>\n",
       "      <td>-1.530292</td>\n",
       "      <td>1.086553</td>\n",
       "      <td>-2.238316</td>\n",
       "      <td>2.464141</td>\n",
       "      <td>-0.457655</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>456 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           RI        Na        Mg        Al        Si         K        Ca  \\\n",
       "0    1.005995 -0.037941  1.521530 -0.763869 -0.969247 -0.481384 -0.212195   \n",
       "1   -0.159261  0.212652  0.947370 -0.310299  0.036400 -0.011003 -0.841935   \n",
       "2   -0.649353 -0.148202  0.915114  0.003711  0.311630 -0.111799 -0.876160   \n",
       "3   -0.142124 -0.468960  1.005431 -0.432414 -0.090629  0.089793 -0.574980   \n",
       "4   -0.224378 -0.408818  0.960273 -0.519639  0.406902  0.067394 -0.677655   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "451 -0.303204  1.074692 -1.375076  0.806181  0.343387 -0.548582 -0.362785   \n",
       "452 -0.426584  0.884241 -1.375076  0.771291  0.629203 -0.548582 -0.369630   \n",
       "453 -0.652781  1.275166 -1.375076  1.277195  0.639788 -0.548582 -0.239575   \n",
       "454 -0.258650  1.275166 -1.375076  0.457281  0.311630 -0.548582 -0.308025   \n",
       "455  0.104635  0.643672  0.728028  1.189970 -1.530292  1.086553 -2.238316   \n",
       "\n",
       "           Ba        Fe  Type  \n",
       "0   -0.414563 -0.457655     1  \n",
       "1   -0.414563 -0.457655     1  \n",
       "2   -0.414563 -0.457655     1  \n",
       "3   -0.414563 -0.457655     1  \n",
       "4   -0.414563 -0.457655     1  \n",
       "..        ...       ...   ...  \n",
       "451  2.393498  0.311712     7  \n",
       "452  2.358176  0.215541     7  \n",
       "453  0.768708 -0.457655     7  \n",
       "454  2.322855 -0.457655     7  \n",
       "455  2.464141 -0.457655     7  \n",
       "\n",
       "[456 rows x 10 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sample_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "75d4fe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_sample_scale.drop(columns=['Type'])\n",
    "y = data_sample_scale['Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "38c9f8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    76\n",
       "2    76\n",
       "3    76\n",
       "5    76\n",
       "6    76\n",
       "7    76\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c89143bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.replace({1:0,2:1,3:2,5:3,6:4,7:5},)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "031a4060",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X,y, test_size=0.2,random_state=21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "11cffa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = {'Logistic': LogisticRegression(),\n",
    "         'KNN': KNeighborsClassifier(),\n",
    "         'Naive Bayes': GaussianNB(),\n",
    "         'Decision Tree': DecisionTreeClassifier(),\n",
    "         'RandomForest': RandomForestClassifier(),\n",
    "         'AdaBoost': AdaBoostClassifier(),\n",
    "         'GBM': GradientBoostingClassifier(),\n",
    "         'Xgboost': xgb.XGBClassifier(),\n",
    "         'Voting_hard': VotingClassifier(estimators=[('lr', LogisticRegression()), \n",
    "                                                ('rf', RandomForestClassifier()), \n",
    "                                                ('gmb', GradientBoostingClassifier())], \n",
    "                                    voting='hard'),\n",
    "         'Voting_soft': VotingClassifier(estimators=[('lr', LogisticRegression()), \n",
    "                                                ('rf', RandomForestClassifier()), \n",
    "                                                ('gmb', GradientBoostingClassifier())], \n",
    "                                    voting='soft'),\n",
    "         'Voting_soft_best_model': VotingClassifier(estimators=[('xgb', xgb.XGBClassifier()), \n",
    "                                                ('rf', RandomForestClassifier()), \n",
    "                                                ('gmb', GradientBoostingClassifier())], \n",
    "                                    voting='soft'),\n",
    "         'Stacking': StackingClassifier(estimators=[('lr', LogisticRegression()), \n",
    "                                                ('rf', RandomForestClassifier()), \n",
    "                                                ('gmb', GradientBoostingClassifier())], \n",
    "                                     final_estimator=LogisticRegression()),\n",
    "         'Stacking_best_model': StackingClassifier(estimators=[('xgb', xgb.XGBClassifier()),  \n",
    "                                                ('rf', RandomForestClassifier()), \n",
    "                                                ('gmb', GradientBoostingClassifier())], \n",
    "                                     final_estimator=DecisionTreeClassifier()),\n",
    "         'Stacking_best_model_best_final_estimator': StackingClassifier(estimators=[('xgb', xgb.XGBClassifier()),  \n",
    "                                                ('rf', RandomForestClassifier()), \n",
    "                                                ('gmb', GradientBoostingClassifier())], \n",
    "                                     final_estimator=RandomForestClassifier()),   \n",
    "          \n",
    "          \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c37eeecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model :  Logistic\n",
      "Train Accuracy :  0.8461538461538461\n",
      "Test Accuracy :  0.8043478260869565\n",
      "Train Confusion Matrix :  [[36 12  8  0  0  0]\n",
      " [11 29 15  2  2  1]\n",
      " [ 0  1 63  0  0  0]\n",
      " [ 0  0  0 60  0  0]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 2  2  0  0  0 59]]\n",
      "Test Confusion Matrix :  [[13  5  2  0  0  0]\n",
      " [ 3  7  4  2  0  0]\n",
      " [ 0  1 11  0  0  0]\n",
      " [ 0  0  0 16  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  0  0  1  0 12]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.64      0.69        56\n",
      "           1       0.66      0.48      0.56        60\n",
      "           2       0.73      0.98      0.84        64\n",
      "           3       0.97      1.00      0.98        60\n",
      "           4       0.97      1.00      0.98        61\n",
      "           5       0.98      0.94      0.96        63\n",
      "\n",
      "    accuracy                           0.85       364\n",
      "   macro avg       0.84      0.84      0.84       364\n",
      "weighted avg       0.84      0.85      0.84       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.65      0.72        20\n",
      "           1       0.54      0.44      0.48        16\n",
      "           2       0.65      0.92      0.76        12\n",
      "           3       0.84      1.00      0.91        16\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.80        92\n",
      "   macro avg       0.81      0.82      0.81        92\n",
      "weighted avg       0.81      0.80      0.80        92\n",
      "\n",
      "Model :  KNN\n",
      "Train Accuracy :  0.8956043956043956\n",
      "Test Accuracy :  0.8478260869565217\n",
      "Train Confusion Matrix :  [[42  3 11  0  0  0]\n",
      " [ 9 42  5  2  2  0]\n",
      " [ 2  0 62  0  0  0]\n",
      " [ 0  0  0 60  0  0]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 2  0  0  2  0 59]]\n",
      "Test Confusion Matrix :  [[16  1  3  0  0  0]\n",
      " [ 6  8  1  1  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0  0 16  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  0  0  2  0 11]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.75      0.76        56\n",
      "           1       0.93      0.70      0.80        60\n",
      "           2       0.79      0.97      0.87        64\n",
      "           3       0.94      1.00      0.97        60\n",
      "           4       0.97      1.00      0.98        61\n",
      "           5       1.00      0.94      0.97        63\n",
      "\n",
      "    accuracy                           0.90       364\n",
      "   macro avg       0.90      0.89      0.89       364\n",
      "weighted avg       0.90      0.90      0.89       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.76        20\n",
      "           1       0.89      0.50      0.64        16\n",
      "           2       0.75      1.00      0.86        12\n",
      "           3       0.84      1.00      0.91        16\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       1.00      0.85      0.92        13\n",
      "\n",
      "    accuracy                           0.85        92\n",
      "   macro avg       0.87      0.86      0.85        92\n",
      "weighted avg       0.86      0.85      0.84        92\n",
      "\n",
      "Model :  Naive Bayes\n",
      "Train Accuracy :  0.6730769230769231\n",
      "Test Accuracy :  0.6086956521739131\n",
      "Train Confusion Matrix :  [[12  4 38  0  2  0]\n",
      " [10  9 33  4  3  1]\n",
      " [ 3  0 55  0  6  0]\n",
      " [ 0 11  0 49  0  0]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 0  0  2  2  0 59]]\n",
      "Test Confusion Matrix :  [[ 6  1 13  0  0  0]\n",
      " [ 2  2 10  2  0  0]\n",
      " [ 3  0  8  0  1  0]\n",
      " [ 0  3  0 13  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  0  0  1  0 12]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.21      0.30        56\n",
      "           1       0.38      0.15      0.21        60\n",
      "           2       0.43      0.86      0.57        64\n",
      "           3       0.89      0.82      0.85        60\n",
      "           4       0.85      1.00      0.92        61\n",
      "           5       0.98      0.94      0.96        63\n",
      "\n",
      "    accuracy                           0.67       364\n",
      "   macro avg       0.67      0.66      0.64       364\n",
      "weighted avg       0.67      0.67      0.64       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.30      0.39        20\n",
      "           1       0.33      0.12      0.18        16\n",
      "           2       0.26      0.67      0.37        12\n",
      "           3       0.81      0.81      0.81        16\n",
      "           4       0.94      1.00      0.97        15\n",
      "           5       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.61        92\n",
      "   macro avg       0.65      0.64      0.61        92\n",
      "weighted avg       0.65      0.61      0.60        92\n",
      "\n",
      "Model :  Decision Tree\n",
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.8695652173913043\n",
      "Train Confusion Matrix :  [[56  0  0  0  0  0]\n",
      " [ 0 60  0  0  0  0]\n",
      " [ 0  0 64  0  0  0]\n",
      " [ 0  0  0 60  0  0]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 0  0  0  0  0 63]]\n",
      "Test Confusion Matrix :  [[16  1  3  0  0  0]\n",
      " [ 5  9  1  1  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0  0 16  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  0  0  1  0 12]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        56\n",
      "           1       1.00      1.00      1.00        60\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00        60\n",
      "           4       1.00      1.00      1.00        61\n",
      "           5       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       364\n",
      "   macro avg       1.00      1.00      1.00       364\n",
      "weighted avg       1.00      1.00      1.00       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.80      0.78        20\n",
      "           1       0.90      0.56      0.69        16\n",
      "           2       0.75      1.00      0.86        12\n",
      "           3       0.89      1.00      0.94        16\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.87        92\n",
      "   macro avg       0.88      0.88      0.87        92\n",
      "weighted avg       0.88      0.87      0.86        92\n",
      "\n",
      "Model :  RandomForest\n",
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.8913043478260869\n",
      "Train Confusion Matrix :  [[56  0  0  0  0  0]\n",
      " [ 0 60  0  0  0  0]\n",
      " [ 0  0 64  0  0  0]\n",
      " [ 0  0  0 60  0  0]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 0  0  0  0  0 63]]\n",
      "Test Confusion Matrix :  [[18  0  2  0  0  0]\n",
      " [ 5  9  1  1  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0  0 16  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  0  0  1  0 12]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        56\n",
      "           1       1.00      1.00      1.00        60\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00        60\n",
      "           4       1.00      1.00      1.00        61\n",
      "           5       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       364\n",
      "   macro avg       1.00      1.00      1.00       364\n",
      "weighted avg       1.00      1.00      1.00       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.90      0.84        20\n",
      "           1       1.00      0.56      0.72        16\n",
      "           2       0.80      1.00      0.89        12\n",
      "           3       0.89      1.00      0.94        16\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.89        92\n",
      "   macro avg       0.91      0.90      0.89        92\n",
      "weighted avg       0.91      0.89      0.89        92\n",
      "\n",
      "Model :  AdaBoost\n",
      "Train Accuracy :  0.6016483516483516\n",
      "Test Accuracy :  0.532608695652174\n",
      "Train Confusion Matrix :  [[ 0 25 31  0  0  0]\n",
      " [ 0 18 32  4  6  0]\n",
      " [ 0 35 29  0  0  0]\n",
      " [ 0  0  0 50  4  6]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 0  2  0  0  0 61]]\n",
      "Test Confusion Matrix :  [[ 0  4 16  0  0  0]\n",
      " [ 0  4  9  2  1  0]\n",
      " [ 0  9  3  0  0  0]\n",
      " [ 0  0  0 15  1  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  0  0  1  0 12]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        56\n",
      "           1       0.23      0.30      0.26        60\n",
      "           2       0.32      0.45      0.37        64\n",
      "           3       0.93      0.83      0.88        60\n",
      "           4       0.86      1.00      0.92        61\n",
      "           5       0.91      0.97      0.94        63\n",
      "\n",
      "    accuracy                           0.60       364\n",
      "   macro avg       0.54      0.59      0.56       364\n",
      "weighted avg       0.55      0.60      0.57       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        20\n",
      "           1       0.24      0.25      0.24        16\n",
      "           2       0.11      0.25      0.15        12\n",
      "           3       0.83      0.94      0.88        16\n",
      "           4       0.88      1.00      0.94        15\n",
      "           5       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.53        92\n",
      "   macro avg       0.51      0.56      0.53        92\n",
      "weighted avg       0.48      0.53      0.50        92\n",
      "\n",
      "Model :  GBM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamednoordeenalaudeen/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohamednoordeenalaudeen/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohamednoordeenalaudeen/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohamednoordeenalaudeen/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohamednoordeenalaudeen/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohamednoordeenalaudeen/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.9021739130434783\n",
      "Train Confusion Matrix :  [[56  0  0  0  0  0]\n",
      " [ 0 60  0  0  0  0]\n",
      " [ 0  0 64  0  0  0]\n",
      " [ 0  0  0 60  0  0]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 0  0  0  0  0 63]]\n",
      "Test Confusion Matrix :  [[17  1  2  0  0  0]\n",
      " [ 4 11  1  0  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0  0 16  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  1  0  0  0 12]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        56\n",
      "           1       1.00      1.00      1.00        60\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00        60\n",
      "           4       1.00      1.00      1.00        61\n",
      "           5       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       364\n",
      "   macro avg       1.00      1.00      1.00       364\n",
      "weighted avg       1.00      1.00      1.00       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83        20\n",
      "           1       0.85      0.69      0.76        16\n",
      "           2       0.80      1.00      0.89        12\n",
      "           3       1.00      1.00      1.00        16\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.90        92\n",
      "   macro avg       0.91      0.91      0.91        92\n",
      "weighted avg       0.91      0.90      0.90        92\n",
      "\n",
      "Model :  Xgboost\n",
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.8804347826086957\n",
      "Train Confusion Matrix :  [[56  0  0  0  0  0]\n",
      " [ 0 60  0  0  0  0]\n",
      " [ 0  0 64  0  0  0]\n",
      " [ 0  0  0 60  0  0]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 0  0  0  0  0 63]]\n",
      "Test Confusion Matrix :  [[16  2  2  0  0  0]\n",
      " [ 4 10  1  1  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0  0 16  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  0  0  1  0 12]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        56\n",
      "           1       1.00      1.00      1.00        60\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00        60\n",
      "           4       1.00      1.00      1.00        61\n",
      "           5       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       364\n",
      "   macro avg       1.00      1.00      1.00       364\n",
      "weighted avg       1.00      1.00      1.00       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80        20\n",
      "           1       0.83      0.62      0.71        16\n",
      "           2       0.80      1.00      0.89        12\n",
      "           3       0.89      1.00      0.94        16\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.88        92\n",
      "   macro avg       0.89      0.89      0.88        92\n",
      "weighted avg       0.88      0.88      0.88        92\n",
      "\n",
      "Model :  Voting_hard\n",
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.8695652173913043\n",
      "Train Confusion Matrix :  [[56  0  0  0  0  0]\n",
      " [ 0 60  0  0  0  0]\n",
      " [ 0  0 64  0  0  0]\n",
      " [ 0  0  0 60  0  0]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 0  0  0  0  0 63]]\n",
      "Test Confusion Matrix :  [[17  1  2  0  0  0]\n",
      " [ 6  8  1  1  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0  0 16  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  0  0  1  0 12]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        56\n",
      "           1       1.00      1.00      1.00        60\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00        60\n",
      "           4       1.00      1.00      1.00        61\n",
      "           5       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       364\n",
      "   macro avg       1.00      1.00      1.00       364\n",
      "weighted avg       1.00      1.00      1.00       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79        20\n",
      "           1       0.89      0.50      0.64        16\n",
      "           2       0.80      1.00      0.89        12\n",
      "           3       0.89      1.00      0.94        16\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.87        92\n",
      "   macro avg       0.89      0.88      0.87        92\n",
      "weighted avg       0.88      0.87      0.86        92\n",
      "\n",
      "Model :  Voting_soft\n",
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.8913043478260869\n",
      "Train Confusion Matrix :  [[56  0  0  0  0  0]\n",
      " [ 0 60  0  0  0  0]\n",
      " [ 0  0 64  0  0  0]\n",
      " [ 0  0  0 60  0  0]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 0  0  0  0  0 63]]\n",
      "Test Confusion Matrix :  [[17  1  2  0  0  0]\n",
      " [ 4 10  1  1  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0  0 16  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  0  0  1  0 12]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        56\n",
      "           1       1.00      1.00      1.00        60\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00        60\n",
      "           4       1.00      1.00      1.00        61\n",
      "           5       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       364\n",
      "   macro avg       1.00      1.00      1.00       364\n",
      "weighted avg       1.00      1.00      1.00       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83        20\n",
      "           1       0.91      0.62      0.74        16\n",
      "           2       0.80      1.00      0.89        12\n",
      "           3       0.89      1.00      0.94        16\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.89        92\n",
      "   macro avg       0.90      0.90      0.89        92\n",
      "weighted avg       0.90      0.89      0.89        92\n",
      "\n",
      "Model :  Voting_soft_best_model\n",
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.8913043478260869\n",
      "Train Confusion Matrix :  [[56  0  0  0  0  0]\n",
      " [ 0 60  0  0  0  0]\n",
      " [ 0  0 64  0  0  0]\n",
      " [ 0  0  0 60  0  0]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 0  0  0  0  0 63]]\n",
      "Test Confusion Matrix :  [[17  1  2  0  0  0]\n",
      " [ 4 10  1  1  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0  0 16  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  1  0  0  0 12]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        56\n",
      "           1       1.00      1.00      1.00        60\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00        60\n",
      "           4       1.00      1.00      1.00        61\n",
      "           5       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       364\n",
      "   macro avg       1.00      1.00      1.00       364\n",
      "weighted avg       1.00      1.00      1.00       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83        20\n",
      "           1       0.83      0.62      0.71        16\n",
      "           2       0.80      1.00      0.89        12\n",
      "           3       0.94      1.00      0.97        16\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.89        92\n",
      "   macro avg       0.90      0.90      0.89        92\n",
      "weighted avg       0.89      0.89      0.89        92\n",
      "\n",
      "Model :  Stacking\n",
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.8913043478260869\n",
      "Train Confusion Matrix :  [[56  0  0  0  0  0]\n",
      " [ 0 60  0  0  0  0]\n",
      " [ 0  0 64  0  0  0]\n",
      " [ 0  0  0 60  0  0]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 0  0  0  0  0 63]]\n",
      "Test Confusion Matrix :  [[17  1  2  0  0  0]\n",
      " [ 4 10  1  1  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0  0 16  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  1  0  0  0 12]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        56\n",
      "           1       1.00      1.00      1.00        60\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00        60\n",
      "           4       1.00      1.00      1.00        61\n",
      "           5       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       364\n",
      "   macro avg       1.00      1.00      1.00       364\n",
      "weighted avg       1.00      1.00      1.00       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83        20\n",
      "           1       0.83      0.62      0.71        16\n",
      "           2       0.80      1.00      0.89        12\n",
      "           3       0.94      1.00      0.97        16\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.89        92\n",
      "   macro avg       0.90      0.90      0.89        92\n",
      "weighted avg       0.89      0.89      0.89        92\n",
      "\n",
      "Model :  Stacking_best_model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  0.9862637362637363\n",
      "Test Accuracy :  0.9239130434782609\n",
      "Train Confusion Matrix :  [[56  0  0  0  0  0]\n",
      " [ 4 56  0  0  0  0]\n",
      " [ 0  1 63  0  0  0]\n",
      " [ 0  0  0 60  0  0]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 0  0  0  0  0 63]]\n",
      "Test Confusion Matrix :  [[18  1  1  0  0  0]\n",
      " [ 3 13  0  0  0  0]\n",
      " [ 0  1 11  0  0  0]\n",
      " [ 0  0  0 16  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  1  0  0  0 12]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        56\n",
      "           1       0.98      0.93      0.96        60\n",
      "           2       1.00      0.98      0.99        64\n",
      "           3       1.00      1.00      1.00        60\n",
      "           4       1.00      1.00      1.00        61\n",
      "           5       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           0.99       364\n",
      "   macro avg       0.99      0.99      0.99       364\n",
      "weighted avg       0.99      0.99      0.99       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        20\n",
      "           1       0.81      0.81      0.81        16\n",
      "           2       0.92      0.92      0.92        12\n",
      "           3       1.00      1.00      1.00        16\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.92        92\n",
      "   macro avg       0.93      0.93      0.93        92\n",
      "weighted avg       0.93      0.92      0.92        92\n",
      "\n",
      "Model :  Stacking_best_model_best_final_estimator\n",
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.9130434782608695\n",
      "Train Confusion Matrix :  [[56  0  0  0  0  0]\n",
      " [ 0 60  0  0  0  0]\n",
      " [ 0  0 64  0  0  0]\n",
      " [ 0  0  0 60  0  0]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 0  0  0  0  0 63]]\n",
      "Test Confusion Matrix :  [[18  1  1  0  0  0]\n",
      " [ 4 11  1  0  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0  0 16  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  1  0  0  0 12]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        56\n",
      "           1       1.00      1.00      1.00        60\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00        60\n",
      "           4       1.00      1.00      1.00        61\n",
      "           5       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       364\n",
      "   macro avg       1.00      1.00      1.00       364\n",
      "weighted avg       1.00      1.00      1.00       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86        20\n",
      "           1       0.85      0.69      0.76        16\n",
      "           2       0.86      1.00      0.92        12\n",
      "           3       1.00      1.00      1.00        16\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.91        92\n",
      "   macro avg       0.92      0.92      0.92        92\n",
      "weighted avg       0.92      0.91      0.91        92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = []\n",
    "for name, model in model_.items():\n",
    "    print(\"Model : \",name)\n",
    "    model.fit(train_X,train_y)\n",
    "    train_pred = model.predict(train_X)\n",
    "    test_pred = model.predict(test_X)\n",
    "    print(\"Train Accuracy : \",accuracy_score(train_y, train_pred))\n",
    "    print(\"Test Accuracy : \",accuracy_score(test_y, test_pred))\n",
    "    print(\"Train Confusion Matrix : \",confusion_matrix(train_y, train_pred))\n",
    "    print(\"Test Confusion Matrix : \",confusion_matrix(test_y, test_pred))\n",
    "    print(\"Train Classification Report : \",classification_report(train_y, train_pred))\n",
    "    print(\"Test Classification Report : \",classification_report(test_y, test_pred))\n",
    "    res.append([name,accuracy_score(train_y, train_pred), accuracy_score(test_y, test_pred)])\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5f2bdf91",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ = pd.DataFrame(res, columns=['Model','Train Accuracy','Test Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "f0a72d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "24a6e092",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X_poly,y, test_size=0.2,random_state=21)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082612e0",
   "metadata": {},
   "source": [
    "# With Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "47e0c469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model :  Logistic\n",
      "Train Accuracy :  0.9285714285714286\n",
      "Test Accuracy :  0.8586956521739131\n",
      "Train Confusion Matrix :  [[44  8  4  0  0  0]\n",
      " [ 9 46  4  1  0  0]\n",
      " [ 0  0 64  0  0  0]\n",
      " [ 0  0  0 60  0  0]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 0  0  0  0  0 63]]\n",
      "Test Confusion Matrix :  [[17  0  3  0  0  0]\n",
      " [ 7  7  1  1  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0  0 16  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  0  0  1  0 12]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81        56\n",
      "           1       0.85      0.77      0.81        60\n",
      "           2       0.89      1.00      0.94        64\n",
      "           3       0.98      1.00      0.99        60\n",
      "           4       1.00      1.00      1.00        61\n",
      "           5       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           0.93       364\n",
      "   macro avg       0.93      0.93      0.92       364\n",
      "weighted avg       0.93      0.93      0.93       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.85      0.77        20\n",
      "           1       1.00      0.44      0.61        16\n",
      "           2       0.75      1.00      0.86        12\n",
      "           3       0.89      1.00      0.94        16\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.86        92\n",
      "   macro avg       0.89      0.87      0.86        92\n",
      "weighted avg       0.88      0.86      0.85        92\n",
      "\n",
      "Model :  KNN\n",
      "Train Accuracy :  0.8956043956043956\n",
      "Test Accuracy :  0.8152173913043478\n",
      "Train Confusion Matrix :  [[44  3  9  0  0  0]\n",
      " [ 9 40  6  2  3  0]\n",
      " [ 0  0 64  0  0  0]\n",
      " [ 0  0  0 60  0  0]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 2  2  0  2  0 57]]\n",
      "Test Confusion Matrix :  [[15  1  4  0  0  0]\n",
      " [ 6  6  2  1  1  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0  0 16  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  1  0  1  0 11]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.79        56\n",
      "           1       0.89      0.67      0.76        60\n",
      "           2       0.81      1.00      0.90        64\n",
      "           3       0.94      1.00      0.97        60\n",
      "           4       0.95      1.00      0.98        61\n",
      "           5       1.00      0.90      0.95        63\n",
      "\n",
      "    accuracy                           0.90       364\n",
      "   macro avg       0.90      0.89      0.89       364\n",
      "weighted avg       0.90      0.90      0.89       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.75      0.73        20\n",
      "           1       0.75      0.38      0.50        16\n",
      "           2       0.67      1.00      0.80        12\n",
      "           3       0.89      1.00      0.94        16\n",
      "           4       0.94      1.00      0.97        15\n",
      "           5       1.00      0.85      0.92        13\n",
      "\n",
      "    accuracy                           0.82        92\n",
      "   macro avg       0.83      0.83      0.81        92\n",
      "weighted avg       0.82      0.82      0.80        92\n",
      "\n",
      "Model :  Naive Bayes\n",
      "Train Accuracy :  0.6318681318681318\n",
      "Test Accuracy :  0.6195652173913043\n",
      "Train Confusion Matrix :  [[31  1 21  0  2  1]\n",
      " [41  9  8  0  1  1]\n",
      " [ 3  0 55  0  6  0]\n",
      " [ 0 34  0 19  0  7]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 2  2  0  4  0 55]]\n",
      "Test Confusion Matrix :  [[ 9  1 10  0  0  0]\n",
      " [ 8  3  4  1  0  0]\n",
      " [ 0  0 11  0  1  0]\n",
      " [ 0  7  0  8  0  1]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  0  0  2  0 11]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.55      0.47        56\n",
      "           1       0.20      0.15      0.17        60\n",
      "           2       0.65      0.86      0.74        64\n",
      "           3       0.83      0.32      0.46        60\n",
      "           4       0.87      1.00      0.93        61\n",
      "           5       0.86      0.87      0.87        63\n",
      "\n",
      "    accuracy                           0.63       364\n",
      "   macro avg       0.63      0.63      0.61       364\n",
      "weighted avg       0.64      0.63      0.61       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.45      0.49        20\n",
      "           1       0.27      0.19      0.22        16\n",
      "           2       0.44      0.92      0.59        12\n",
      "           3       0.73      0.50      0.59        16\n",
      "           4       0.94      1.00      0.97        15\n",
      "           5       0.92      0.85      0.88        13\n",
      "\n",
      "    accuracy                           0.62        92\n",
      "   macro avg       0.64      0.65      0.62        92\n",
      "weighted avg       0.63      0.62      0.61        92\n",
      "\n",
      "Model :  Decision Tree\n",
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.8804347826086957\n",
      "Train Confusion Matrix :  [[56  0  0  0  0  0]\n",
      " [ 0 60  0  0  0  0]\n",
      " [ 0  0 64  0  0  0]\n",
      " [ 0  0  0 60  0  0]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 0  0  0  0  0 63]]\n",
      "Test Confusion Matrix :  [[16  2  2  0  0  0]\n",
      " [ 3 10  3  0  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0  0 16  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  0  0  1  0 12]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        56\n",
      "           1       1.00      1.00      1.00        60\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00        60\n",
      "           4       1.00      1.00      1.00        61\n",
      "           5       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       364\n",
      "   macro avg       1.00      1.00      1.00       364\n",
      "weighted avg       1.00      1.00      1.00       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.80      0.82        20\n",
      "           1       0.83      0.62      0.71        16\n",
      "           2       0.71      1.00      0.83        12\n",
      "           3       0.94      1.00      0.97        16\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.88        92\n",
      "   macro avg       0.89      0.89      0.88        92\n",
      "weighted avg       0.89      0.88      0.88        92\n",
      "\n",
      "Model :  RandomForest\n",
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.9021739130434783\n",
      "Train Confusion Matrix :  [[56  0  0  0  0  0]\n",
      " [ 0 60  0  0  0  0]\n",
      " [ 0  0 64  0  0  0]\n",
      " [ 0  0  0 60  0  0]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 0  0  0  0  0 63]]\n",
      "Test Confusion Matrix :  [[19  0  1  0  0  0]\n",
      " [ 5  9  1  1  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0  0 16  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  0  0  1  0 12]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        56\n",
      "           1       1.00      1.00      1.00        60\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00        60\n",
      "           4       1.00      1.00      1.00        61\n",
      "           5       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       364\n",
      "   macro avg       1.00      1.00      1.00       364\n",
      "weighted avg       1.00      1.00      1.00       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.86        20\n",
      "           1       1.00      0.56      0.72        16\n",
      "           2       0.86      1.00      0.92        12\n",
      "           3       0.89      1.00      0.94        16\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.90        92\n",
      "   macro avg       0.92      0.91      0.90        92\n",
      "weighted avg       0.92      0.90      0.90        92\n",
      "\n",
      "Model :  AdaBoost\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamednoordeenalaudeen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  0.4835164835164835\n",
      "Test Accuracy :  0.45652173913043476\n",
      "Train Confusion Matrix :  [[ 3 51  2  0  0  0]\n",
      " [ 0 49  1  0  9  1]\n",
      " [ 1 57  6  0  0  0]\n",
      " [ 0  0  0  0 54  6]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 0  2  0  0  4 57]]\n",
      "Test Confusion Matrix :  [[ 2 18  0  0  0  0]\n",
      " [ 0 13  0  0  3  0]\n",
      " [ 1 11  0  0  0  0]\n",
      " [ 0  0  0  0 16  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  0  0  0  1 12]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.05      0.10        56\n",
      "           1       0.31      0.82      0.45        60\n",
      "           2       0.67      0.09      0.16        64\n",
      "           3       0.00      0.00      0.00        60\n",
      "           4       0.48      1.00      0.65        61\n",
      "           5       0.89      0.90      0.90        63\n",
      "\n",
      "    accuracy                           0.48       364\n",
      "   macro avg       0.52      0.48      0.38       364\n",
      "weighted avg       0.52      0.48      0.38       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.10      0.17        20\n",
      "           1       0.31      0.81      0.45        16\n",
      "           2       0.00      0.00      0.00        12\n",
      "           3       0.00      0.00      0.00        16\n",
      "           4       0.43      1.00      0.60        15\n",
      "           5       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.46        92\n",
      "   macro avg       0.40      0.47      0.36        92\n",
      "weighted avg       0.41      0.46      0.35        92\n",
      "\n",
      "Model :  GBM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamednoordeenalaudeen/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohamednoordeenalaudeen/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohamednoordeenalaudeen/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohamednoordeenalaudeen/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohamednoordeenalaudeen/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/mohamednoordeenalaudeen/opt/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.9021739130434783\n",
      "Train Confusion Matrix :  [[56  0  0  0  0  0]\n",
      " [ 0 60  0  0  0  0]\n",
      " [ 0  0 64  0  0  0]\n",
      " [ 0  0  0 60  0  0]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 0  0  0  0  0 63]]\n",
      "Test Confusion Matrix :  [[18  1  1  0  0  0]\n",
      " [ 4 10  1  1  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0  0 16  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  0  1  0  0 12]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        56\n",
      "           1       1.00      1.00      1.00        60\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00        60\n",
      "           4       1.00      1.00      1.00        61\n",
      "           5       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       364\n",
      "   macro avg       1.00      1.00      1.00       364\n",
      "weighted avg       1.00      1.00      1.00       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86        20\n",
      "           1       0.91      0.62      0.74        16\n",
      "           2       0.80      1.00      0.89        12\n",
      "           3       0.94      1.00      0.97        16\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.90        92\n",
      "   macro avg       0.91      0.91      0.90        92\n",
      "weighted avg       0.91      0.90      0.90        92\n",
      "\n",
      "Model :  Xgboost\n",
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.9130434782608695\n",
      "Train Confusion Matrix :  [[56  0  0  0  0  0]\n",
      " [ 0 60  0  0  0  0]\n",
      " [ 0  0 64  0  0  0]\n",
      " [ 0  0  0 60  0  0]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 0  0  0  0  0 63]]\n",
      "Test Confusion Matrix :  [[19  0  1  0  0  0]\n",
      " [ 4 10  1  1  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0  0 16  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  0  0  1  0 12]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        56\n",
      "           1       1.00      1.00      1.00        60\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00        60\n",
      "           4       1.00      1.00      1.00        61\n",
      "           5       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       364\n",
      "   macro avg       1.00      1.00      1.00       364\n",
      "weighted avg       1.00      1.00      1.00       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.88        20\n",
      "           1       1.00      0.62      0.77        16\n",
      "           2       0.86      1.00      0.92        12\n",
      "           3       0.89      1.00      0.94        16\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.91        92\n",
      "   macro avg       0.93      0.92      0.91        92\n",
      "weighted avg       0.92      0.91      0.91        92\n",
      "\n",
      "Model :  Voting_hard\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamednoordeenalaudeen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.9130434782608695\n",
      "Train Confusion Matrix :  [[56  0  0  0  0  0]\n",
      " [ 0 60  0  0  0  0]\n",
      " [ 0  0 64  0  0  0]\n",
      " [ 0  0  0 60  0  0]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 0  0  0  0  0 63]]\n",
      "Test Confusion Matrix :  [[19  0  1  0  0  0]\n",
      " [ 5 10  0  1  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0  0 16  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  0  0  1  0 12]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        56\n",
      "           1       1.00      1.00      1.00        60\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00        60\n",
      "           4       1.00      1.00      1.00        61\n",
      "           5       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       364\n",
      "   macro avg       1.00      1.00      1.00       364\n",
      "weighted avg       1.00      1.00      1.00       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.86        20\n",
      "           1       1.00      0.62      0.77        16\n",
      "           2       0.92      1.00      0.96        12\n",
      "           3       0.89      1.00      0.94        16\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.91        92\n",
      "   macro avg       0.93      0.92      0.92        92\n",
      "weighted avg       0.93      0.91      0.91        92\n",
      "\n",
      "Model :  Voting_soft\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamednoordeenalaudeen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.9021739130434783\n",
      "Train Confusion Matrix :  [[56  0  0  0  0  0]\n",
      " [ 0 60  0  0  0  0]\n",
      " [ 0  0 64  0  0  0]\n",
      " [ 0  0  0 60  0  0]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 0  0  0  0  0 63]]\n",
      "Test Confusion Matrix :  [[19  0  1  0  0  0]\n",
      " [ 6  9  0  1  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0  0 16  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  0  0  1  0 12]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        56\n",
      "           1       1.00      1.00      1.00        60\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00        60\n",
      "           4       1.00      1.00      1.00        61\n",
      "           5       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       364\n",
      "   macro avg       1.00      1.00      1.00       364\n",
      "weighted avg       1.00      1.00      1.00       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.95      0.84        20\n",
      "           1       1.00      0.56      0.72        16\n",
      "           2       0.92      1.00      0.96        12\n",
      "           3       0.89      1.00      0.94        16\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.90        92\n",
      "   macro avg       0.93      0.91      0.90        92\n",
      "weighted avg       0.92      0.90      0.90        92\n",
      "\n",
      "Model :  Voting_soft_best_model\n",
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.9239130434782609\n",
      "Train Confusion Matrix :  [[56  0  0  0  0  0]\n",
      " [ 0 60  0  0  0  0]\n",
      " [ 0  0 64  0  0  0]\n",
      " [ 0  0  0 60  0  0]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 0  0  0  0  0 63]]\n",
      "Test Confusion Matrix :  [[19  0  1  0  0  0]\n",
      " [ 3 11  1  1  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0  0 16  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  0  0  1  0 12]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        56\n",
      "           1       1.00      1.00      1.00        60\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00        60\n",
      "           4       1.00      1.00      1.00        61\n",
      "           5       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       364\n",
      "   macro avg       1.00      1.00      1.00       364\n",
      "weighted avg       1.00      1.00      1.00       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90        20\n",
      "           1       1.00      0.69      0.81        16\n",
      "           2       0.86      1.00      0.92        12\n",
      "           3       0.89      1.00      0.94        16\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.92        92\n",
      "   macro avg       0.93      0.93      0.92        92\n",
      "weighted avg       0.93      0.92      0.92        92\n",
      "\n",
      "Model :  Stacking\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mohamednoordeenalaudeen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mohamednoordeenalaudeen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mohamednoordeenalaudeen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mohamednoordeenalaudeen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mohamednoordeenalaudeen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/mohamednoordeenalaudeen/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.9239130434782609\n",
      "Train Confusion Matrix :  [[56  0  0  0  0  0]\n",
      " [ 0 60  0  0  0  0]\n",
      " [ 0  0 64  0  0  0]\n",
      " [ 0  0  0 60  0  0]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 0  0  0  0  0 63]]\n",
      "Test Confusion Matrix :  [[18  1  1  0  0  0]\n",
      " [ 3 12  0  1  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0  0 16  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  0  0  1  0 12]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        56\n",
      "           1       1.00      1.00      1.00        60\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00        60\n",
      "           4       1.00      1.00      1.00        61\n",
      "           5       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       364\n",
      "   macro avg       1.00      1.00      1.00       364\n",
      "weighted avg       1.00      1.00      1.00       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.90      0.88        20\n",
      "           1       0.92      0.75      0.83        16\n",
      "           2       0.92      1.00      0.96        12\n",
      "           3       0.89      1.00      0.94        16\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.92        92\n",
      "   macro avg       0.93      0.93      0.93        92\n",
      "weighted avg       0.93      0.92      0.92        92\n",
      "\n",
      "Model :  Stacking_best_model\n",
      "Train Accuracy :  0.989010989010989\n",
      "Test Accuracy :  0.9130434782608695\n",
      "Train Confusion Matrix :  [[56  0  0  0  0  0]\n",
      " [ 4 56  0  0  0  0]\n",
      " [ 0  0 64  0  0  0]\n",
      " [ 0  0  0 60  0  0]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 0  0  0  0  0 63]]\n",
      "Test Confusion Matrix :  [[19  0  1  0  0  0]\n",
      " [ 6 10  0  0  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0  0 16  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  1  0  0  0 12]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.97        56\n",
      "           1       1.00      0.93      0.97        60\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00        60\n",
      "           4       1.00      1.00      1.00        61\n",
      "           5       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           0.99       364\n",
      "   macro avg       0.99      0.99      0.99       364\n",
      "weighted avg       0.99      0.99      0.99       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.95      0.84        20\n",
      "           1       0.91      0.62      0.74        16\n",
      "           2       0.92      1.00      0.96        12\n",
      "           3       1.00      1.00      1.00        16\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.91        92\n",
      "   macro avg       0.93      0.92      0.92        92\n",
      "weighted avg       0.92      0.91      0.91        92\n",
      "\n",
      "Model :  Stacking_best_model_best_final_estimator\n",
      "Train Accuracy :  1.0\n",
      "Test Accuracy :  0.9130434782608695\n",
      "Train Confusion Matrix :  [[56  0  0  0  0  0]\n",
      " [ 0 60  0  0  0  0]\n",
      " [ 0  0 64  0  0  0]\n",
      " [ 0  0  0 60  0  0]\n",
      " [ 0  0  0  0 61  0]\n",
      " [ 0  0  0  0  0 63]]\n",
      "Test Confusion Matrix :  [[19  0  1  0  0  0]\n",
      " [ 5 10  0  1  0  0]\n",
      " [ 0  0 12  0  0  0]\n",
      " [ 0  0  0 16  0  0]\n",
      " [ 0  0  0  0 15  0]\n",
      " [ 0  1  0  0  0 12]]\n",
      "Train Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        56\n",
      "           1       1.00      1.00      1.00        60\n",
      "           2       1.00      1.00      1.00        64\n",
      "           3       1.00      1.00      1.00        60\n",
      "           4       1.00      1.00      1.00        61\n",
      "           5       1.00      1.00      1.00        63\n",
      "\n",
      "    accuracy                           1.00       364\n",
      "   macro avg       1.00      1.00      1.00       364\n",
      "weighted avg       1.00      1.00      1.00       364\n",
      "\n",
      "Test Classification Report :                precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.86        20\n",
      "           1       0.91      0.62      0.74        16\n",
      "           2       0.92      1.00      0.96        12\n",
      "           3       0.94      1.00      0.97        16\n",
      "           4       1.00      1.00      1.00        15\n",
      "           5       1.00      0.92      0.96        13\n",
      "\n",
      "    accuracy                           0.91        92\n",
      "   macro avg       0.93      0.92      0.92        92\n",
      "weighted avg       0.92      0.91      0.91        92\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res_poly = []\n",
    "for name, model in model_.items():\n",
    "    print(\"Model : \",name)\n",
    "    model.fit(train_X,train_y)\n",
    "    train_pred = model.predict(train_X)\n",
    "    test_pred = model.predict(test_X)\n",
    "    print(\"Train Accuracy : \",accuracy_score(train_y, train_pred))\n",
    "    print(\"Test Accuracy : \",accuracy_score(test_y, test_pred))\n",
    "    print(\"Train Confusion Matrix : \",confusion_matrix(train_y, train_pred))\n",
    "    print(\"Test Confusion Matrix : \",confusion_matrix(test_y, test_pred))\n",
    "    print(\"Train Classification Report : \",classification_report(train_y, train_pred))\n",
    "    print(\"Test Classification Report : \",classification_report(test_y, test_pred))\n",
    "    res_poly.append([name+'_polynomial_features',accuracy_score(train_y, train_pred), accuracy_score(test_y, test_pred)])\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "eb329d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_res = pd.DataFrame(res, columns=['Model','Train Accuracy','Test Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "110d8e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Train Accuracy</th>\n",
       "      <th>Test Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.804348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.895604</td>\n",
       "      <td>0.847826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.891304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.601648</td>\n",
       "      <td>0.532609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GBM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.902174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Xgboost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.880435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Voting_hard</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Voting_soft</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.891304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Voting_soft_best_model</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.891304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Stacking</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.891304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Stacking_best_model</td>\n",
       "      <td>0.986264</td>\n",
       "      <td>0.923913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Stacking_best_model_best_final_estimator</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.804348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.895604</td>\n",
       "      <td>0.847826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.608696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.891304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>0.601648</td>\n",
       "      <td>0.532609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GBM</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.902174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Xgboost</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.880435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Voting_hard</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.869565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Voting_soft</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.891304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Voting_soft_best_model</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.891304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Stacking</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.891304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Stacking_best_model</td>\n",
       "      <td>0.986264</td>\n",
       "      <td>0.923913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Stacking_best_model_best_final_estimator</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Model  Train Accuracy  Test Accuracy\n",
       "0                                   Logistic        0.846154       0.804348\n",
       "1                                        KNN        0.895604       0.847826\n",
       "2                                Naive Bayes        0.673077       0.608696\n",
       "3                              Decision Tree        1.000000       0.869565\n",
       "4                               RandomForest        1.000000       0.891304\n",
       "5                                   AdaBoost        0.601648       0.532609\n",
       "6                                        GBM        1.000000       0.902174\n",
       "7                                    Xgboost        1.000000       0.880435\n",
       "8                                Voting_hard        1.000000       0.869565\n",
       "9                                Voting_soft        1.000000       0.891304\n",
       "10                    Voting_soft_best_model        1.000000       0.891304\n",
       "11                                  Stacking        1.000000       0.891304\n",
       "12                       Stacking_best_model        0.986264       0.923913\n",
       "13  Stacking_best_model_best_final_estimator        1.000000       0.913043\n",
       "0                                   Logistic        0.846154       0.804348\n",
       "1                                        KNN        0.895604       0.847826\n",
       "2                                Naive Bayes        0.673077       0.608696\n",
       "3                              Decision Tree        1.000000       0.869565\n",
       "4                               RandomForest        1.000000       0.891304\n",
       "5                                   AdaBoost        0.601648       0.532609\n",
       "6                                        GBM        1.000000       0.902174\n",
       "7                                    Xgboost        1.000000       0.880435\n",
       "8                                Voting_hard        1.000000       0.869565\n",
       "9                                Voting_soft        1.000000       0.891304\n",
       "10                    Voting_soft_best_model        1.000000       0.891304\n",
       "11                                  Stacking        1.000000       0.891304\n",
       "12                       Stacking_best_model        0.986264       0.923913\n",
       "13  Stacking_best_model_best_final_estimator        1.000000       0.913043"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([res_,poly_res])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95588f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4851902c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a94c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "BigMart Sales - DecisionTree, Random forest, Boosting, stacking voting\n",
    "Loan Prediction - \n",
    "Flight Prediction - \n",
    "Cross Sell prediction\n",
    "Black Friday Prediction\n",
    "Titanic Survival prediction\n",
    "Housing Prediction - \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f8b2cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8385d880",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
